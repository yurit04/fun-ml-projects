{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code]\nimport numpy as np\nimport pandas as pd\n\n\n\n# read data\ndf = pd.read_csv('../input/tabular-playground-series-jul-2022/data.csv')\nx  = np.array(df.loc[:,'f_22':'f_28']) # these are the only relevant float vars\n\n\n\n# power transform integer vars to make them look more 'normal'\npower = 0.47 # best value\nx2 = ((1 + np.array(df.loc[:,'f_07':'f_13']))**power - 1) / power\n\n\n\n# init EM means, covariances, support vars\nnc = 7 * 6 # 7 groups of 6 clusters each\nci = np.zeros([nc, 7, 7], dtype=np.float32) # (nc, 7, 7) covariance of integer vars - init to diagonal matrix\nfor i in range(7): ci[:,i,i] = 1\nc  = np.zeros([nc, 5, 5], dtype=np.float32) # (nc, 5, 5) covariance of float vars - init to diagonal matrix. Here 2 uncorrelated vars are removed\nfor i in range(5): c[:,i,i] = 1\n# hardcode float means to points selected by GMM(42) for float vars only - to improve convergence with full data\nm  = np.array([1,-1,-1,-1,-1,1,-1,1,1,-1,-1,-1,1,1,1,1,1,-1,1,-1,-1,1,1,-1,-1,-1,1,1,1,1,1,-1,1,-1,-1,-1,1,-1,1,1,1,1,-1,1,-1,-1,-1,1,-1,-1,\n1,-1,-1,-1,-1,-1,1,1,-1,1,-1,1,1,-1,1,-1,1,1,1,-1,-1,1,1,-1,-1,-1,-1,1,-1,-1,-1,-1,1,-1,1,-1,1,-1,1,-1,\n-1,-1,-1,1,1,1,1,-1,1,-1,1,-1,1,1,-1,1,1,1,1,1,-1,1,1,-1,-1,-1,1,-1,-1,-1,-1,-1,-1,-1,1,-1,-1,-1,-1,-1,\n1,-1,-1,-1,1,-1,-1,1,-1,-1,-1,1,-1,1,-1,-1,1,-1,-1,1,-1,1,-1,-1,-1,1,1,1,1,1,-1,-1,1,1,-1,1,1,1,-1,-1,\n-1,-1,-1,-1,-1,1,-1,-1,-1,1,1,1,1,-1,1,1,-1,1,-1,1,-1,1,-1,-1,1,1,-1,1,1,1,-1,-1,-1,1,1,1,1,1,-1,-1], dtype=np.float32).reshape(nc,5)\nmi = 3.33 * np.ones([nc, 7], dtype=np.float32) # (nc, 7) mean of integer vars. Init to mean of them all\nnon_corr_vars = np.array([0,1, 3,4, 0,5, 1,5, 2,5, 4,5, 4,6]).reshape(7,2) # for 7 cluster groups, indices of 2 vars that are uncorrelated with the rest. They have 0 mean and 1 std.\nprob = np.zeros([x.shape[0], nc], dtype=np.float32) # predicted probability of each point for each cluster\n\n\n\n# custom EM loop\nfor ii in range(20):# 20 iters are enough to converge\n    # 1. Expectation\n    for i in range(nc): # 42 clusters\n        # ints\n        cov = ci[i,:,:]\n        mu  = mi[i,:]\n        p1  = ((x2 - mu.reshape(1,-1)).dot(np.linalg.inv(cov)) * (x2 - mu.reshape(1,-1))).sum(axis=1)\n        p1  = np.exp(-p1/2) / np.linalg.det(cov)**(1/2)\n        # floats part 1 - 5 correlated vars\n        cov = c[i,:,:]\n        mu  = m[i,:]\n        ncv = list(non_corr_vars[i//6,:]) # indices of 2 vars that are uncorrelated with the rest\n        cv  = list(set([0,1,2,3,4,5,6]) - set(ncv)) # indices of 5 vars that are correlated with each other\n        x1  = x[:,cv]\n        p2  = ((x1 - mu.reshape(1,-1)).dot(np.linalg.inv(cov)) * (x1 - mu.reshape(1,-1))).sum(axis=1)\n        p2  = np.exp(-p2/2) / np.linalg.det(cov)**(1/2)\n        # floats part 2 - 2 uncorrelated vars with 0 mean and 1 std\n        x3  = x[:,ncv]\n        p3  = (x3 * x3).sum(axis=1)\n        p3  = np.exp(-p3/2)\n        prob[:,i] = p1 * p2 * p3 # final probability is the product of 3 pieces\n    gm2 = prob.argmax(axis=1)\n    LP  = np.log(prob.max(axis=1)).mean() # log prob - to track convergence\n    print(ii, np.round(LP, 4))\n\n    # 2. Maximization\n    for i in range(7):# ints - 7 cluster groups *******************************************\n        x_cl = x2[(gm2//6)==i,:] # points for this cluster block only\n        # set means to means of x\n        mi[i*6:(i+1)*6,:] = x_cl.mean(axis=0) # int mean is the same for all subclusters\n        # covariance\n        x_cl = x_cl - mi[i*6,:].reshape(1,-1)\n        ci[i*6:(i+1)*6,:,:] = x_cl.T.dot(x_cl) / x_cl.shape[0] # int cov is the same for all subclusters\n        # set cov to 0 if it is close to zero (<.01)\n        c2 = ci[i*6:(i+1)*6,:,:].ravel()\n        c2[(np.abs(c2) < .01)] = .0\n        ci[i*6:(i+1)*6,:,:] = c2.reshape(-1, 7, 7)\n    for i in range(nc):# floats - 42 clusters ******************************************\n        ncv = list(non_corr_vars[i//6,:]) # indices of 2 vars that are uncorrelated with the rest\n        cv  = list(set([0,1,2,3,4,5,6]) - set(ncv)) # indices of 5 vars that are correlated with each other\n        x_cl = x[gm2==i,:] # points for this cluster only\n        # covariance (mean is hardcoded so does not need to be updated)\n        x_cl = x_cl[:,cv] - m[i,:].reshape(1,-1)\n        c[i,:,:] = x_cl.T.dot(x_cl) / x_cl.shape[0]\n\n\n\n# submission\nsub = pd.read_csv('../input/tabular-playground-series-jul-2022/sample_submission.csv')\nsub['Predicted'] = gm2//6\nsub.to_csv('submission.csv', index=False)","metadata":{"_uuid":"0b9833ca-1c9b-402e-adea-233d54d10067","_cell_guid":"66a2bdae-62bf-4309-8860-a890a4e9c61c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}